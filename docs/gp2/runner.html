<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>gp2.runner API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>gp2.runner</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from .data import *
from .gp2 import *
import time
import numpy as np
import os
import tempfile


def validate_weights(weights, tolerance=1e-6):
    &#34;&#34;&#34; Validate the weights for training.
    What must be verified:
        A_train + A_val + A_test = 1. \n
        B_train + B_val + B_test = 1. \n
        A + B + Z = 1. \n
        A * A_test = B. \n
        Z &gt; .1.
    Parameters
    ----------
    weights : dict
        Weights to use for training. If None, will use the default weights.
        Weights should be a dictionary with keys containing the following:
        &#39;A_train&#39;, &#39;A_val&#39;, &#39;A_test&#39;, &#39;B_train&#39;,&#39;B_val&#39;, &#39;B_test&#39;, &#39;A&#39;, &#39;B&#39;,
        &#39;Z&#39;
    tolerance : float
        Tolerance to use for the validation.
    Returns
    -------
    None : None
        If the weights are valid, will return None.
    Raises
    ------
    ValueError
        If the weights are not valid.
    &#34;&#34;&#34;
    # Check if A_train + A_val + A_test = 1
    A_sum = weights[&#39;A_train&#39;] + weights[&#39;A_val&#39;] + weights[&#39;A_test&#39;]
    if not np.isclose(A_sum, 1, rtol=tolerance):
        raise ValueError(&#34;A_train + A_val + A_test must be equal to 1&#34;)

    # Check if B_train + B_val + B_test = 1
    B_sum = weights[&#39;B_train&#39;] + weights[&#39;B_val&#39;] + weights[&#39;B_test&#39;]
    if not np.isclose(B_sum, 1, rtol=tolerance):
        raise ValueError(&#34;B_train + B_val + B_test must be equal to 1&#34;)

    # Check if A + B + Z = 1
    main_sum = weights[&#39;A&#39;] + weights[&#39;B&#39;] + weights[&#39;Z&#39;]
    if not np.isclose(main_sum, 1, rtol=tolerance):
        raise ValueError(&#34;A + B + Z must be equal to 1&#34;)

    # Check if A * A_test = B
    A_mul_A_test = weights[&#39;A&#39;] * weights[&#39;A_test&#39;]
    if not np.isclose(A_mul_A_test, weights[&#39;B&#39;], rtol=tolerance):
        raise ValueError(&#34;A * A_test must be equal to B&#34;)

    # Check if Z &gt; .1
    if weights[&#39;Z&#39;] &lt; .1:
        raise ValueError(&#34;Z must be greater than .1&#34;)

    print(&#34;Weights OK!&#34;)


class Runner:

    def __init__(self,
                 verbose=False,
                 workingdir=tempfile.mkdtemp(suffix=&#39;GP2&#39;),
                 store_after_each_step=False,
                 classifier=None,
                 discriminator=None,
                 weights=None,
                 **kwargs):
        &#34;&#34;&#34; Initialize the GP2 runner with specified classifier and
        discriminator.
        Parameters
        ----------
        verbose : bool
            If True, will print out additional information during training.
        workingdir : str
            Location where to store temporary files and model checkpoints.
        store_after_each_step : bool
            If True, will store the model after each step of the training
            process.
        classifier : str or Classifier
            The classifier to use. If None or &#39;unet&#39;, will use the default
            handcrafted  unet classifier. Supported classifiers are:
            &#39;unet&#39;,&#39;unetplus&#39;, &#39;kattunet2d&#39;, &#39;kunet2d&#39;, &#39;kunetplus2d&#39;,
            &#39;kresunet2d&#39;, &#39;kunet3plus2d&#39;, &#39;kvnet2d&#39;, &#39;kr2unet2d&#39;
        discriminator : str or Discriminator
            The discriminator to use. If None or &#39;cnn&#39;, will use the default
            handcrafted cnn discriminator.
        **kwargs : dict
            Additional keyword arguments to pass to the classifier and
            discriminator.
        &#34;&#34;&#34;

        self.weights = weights
        self.store_after_each_step = store_after_each_step

        self.workingdir = workingdir

        self.verbose = verbose

        self.M = Manager()

        self.dataset_size = None

        # Initialize the classifier
        self.classifier_scores = []
        if classifier is None or isinstance(classifier,
                                            UNet) or classifier == &#39;unet&#39;:
            self.classifier = UNet(verbose=self.verbose,
                                   workingdir=self.workingdir)
        elif isinstance(classifier, KUNet) or classifier == &#39;kvanillaunet&#39;:
            self.classifier = KUNet(verbose=self.verbose,
                                    workingdir=self.workingdir,
                                    **kwargs)
        elif isinstance(classifier, UNetPLUS) or classifier == &#39;unetplus&#39;:
            self.classifier = UNetPLUS(verbose=self.verbose,
                                       workingdir=self.workingdir, **kwargs)
        elif isinstance(classifier, KATTUnet2D) or classifier == &#39;kattunet2d&#39;:
            self.classifier = KATTUnet2D(verbose=self.verbose,
                                         workingdir=self.workingdir,
                                         **kwargs)
        elif isinstance(classifier, KUNet2D) or classifier == &#39;kunet2d&#39;:
            self.classifier = KUNet2D(verbose=self.verbose,
                                      workingdir=self.workingdir, **kwargs)
        elif isinstance(classifier, KUNetPlus2D) or classifier == &#39;kunetplus2d&#39;:
            self.classifier = KUNetPlus2D(verbose=self.verbose,
                                          workingdir=self.workingdir,
                                          **kwargs)
        elif isinstance(classifier, KResUNet2D) or classifier == &#39;kresunet2d&#39;:
            self.classifier = KResUNet2D(verbose=self.verbose,
                                         workingdir=self.workingdir,
                                         **kwargs)
        elif isinstance(classifier,
                        KUNet3Plus2D) or classifier == &#39;kunet3plus2d&#39;:
            self.classifier = KUNet3Plus2D(verbose=self.verbose,
                                           workingdir=self.workingdir,
                                           **kwargs)
        elif isinstance(classifier, KVNet2D) or classifier == &#39;kvnet2d&#39;:
            self.classifier = KVNet2D(verbose=self.verbose,
                                      workingdir=self.workingdir, **kwargs)
        elif isinstance(classifier, KR2UNet2dD) or classifier == &#39;kr2unet2d&#39;:
            self.classifier = KR2UNet2dD(verbose=self.verbose,
                                         workingdir=self.workingdir,
                                         **kwargs)
        else:
            raise ValueError(&#39;Classifier not supported: {}&#39;.format(classifier))

        # Initialize the discriminator
        self.discriminator_scores = []
        if discriminator is None or isinstance(
                discriminator, CNNDiscriminator) or discriminator == &#39;cnn&#39;:
            print(&#39;Using default discriminator (CNN)&#39;)
            self.discriminator = CNNDiscriminator(
                verbose=self.verbose, workingdir=self.workingdir)
        elif isinstance(discriminator,
                        CNNDiscriminatorPLUS) or discriminator == &#39;cnnplus&#39;:
            print(&#39;Using  discriminator (CNN+)&#39;)
            self.discriminator = CNNDiscriminatorPLUS(
                verbose=self.verbose, workingdir=self.workingdir)
        else:
            raise ValueError(&#39;Discriminator not supported: {}&#39;.format(
                discriminator))

    #
    # STEP 0
    #
    def setup_data(self, images, masks, dataset_size=1000, weights=None):
        &#34;&#34;&#34; Set up the data for training.
        Each dataset is composed of three parts:
            A_: data to train/val/test the classifier \n
            B_: expert labels to feed directly into the discriminator \n
            Z_: a repository of additional data that can further train the
            classifier
        Parameters
        ----------
        images : list of np.ndarray
            List of images to use for training.
        masks : list of np.ndarray
            List of masks to use for training.
        dataset_size : int
            Number of images to use for training.
        weights : dict
            Weights to use for training. If None, will use the default weights.
            Weights should be a dictionary with keys &#39;A&#39;, &#39;B&#39;, &#39;Z&#39;, &#39;A_test&#39;.
            The weights should sum to 1.0.
        Returns
        -------
        None
        &#34;&#34;&#34;
        M = self.M

        self.dataset_size = dataset_size
        self.weights = weights

        if weights:
            validate_weights(weights)

        A_, B_, Z_ = Util.create_A_B_Z_split(images, masks,
                                             dataset_size=dataset_size,
                                             weights=weights)

        A = Collection.from_list(A_)
        B = Collection.from_list(B_)
        Z = Collection.from_list(Z_)

        M.register(A, &#39;A&#39;)  # we might not need to save this one here
        M.register(B, &#39;B&#39;)
        M.register(Z, &#39;Z&#39;)

        A = M.get(&#39;A&#39;)
        A_, A_ids = A.to_array()

        # if no weights configured, fallback
        train_count = int(0.4 * 0.1 * dataset_size)
        val_count = int(0.4 * 0.4 * dataset_size)
        test_count = int(0.4 * 0.5 * dataset_size)

        if weights:
            train_count = int(weights[&#39;A&#39;] * weights[&#39;A_train&#39;] * dataset_size)
            val_count = int(weights[&#39;A&#39;] * weights[&#39;A_val&#39;] * dataset_size)
            test_count = int(weights[&#39;A&#39;] * weights[&#39;A_test&#39;] * dataset_size)

        A_train_, A_val_, A_test_ = Util.create_train_val_test_split(
            A_, train_count=train_count, val_count=val_count,
            test_count=test_count, shuffle=False)
        A_train_ids = A_ids[0:train_count]
        A_val_ids = A_ids[train_count:train_count + val_count]
        A_test_ids = A_ids[
                     train_count + val_count:train_count + val_count + test_count]

        A_train = Collection.from_list(A_train_, A_train_ids)  # COLLECTION LAND
        A_val = Collection.from_list(A_val_, A_val_ids)
        A_test = Collection.from_list(A_test_, A_test_ids)

        M.register(A_train, &#39;A_train&#39;)
        M.register(A_val, &#39;A_val&#39;)
        M.register(A_test, &#39;A_test&#39;)

    #
    # STEP 1
    #
    def run_classifier(self, patience_counter=2):
        &#34;&#34;&#34; (Re-)Train the classifier.
        Parameters
        ----------
        patience_counter : int
            Number of epochs to wait before early stopping.
        Returns
        -------
        None
        &#34;&#34;&#34;
        M = self.M

        A_train = M.get(&#39;A_train&#39;)
        A_val = M.get(&#39;A_val&#39;)
        A_test = M.get(&#39;A_test&#39;)

        #
        # ACTUAL CLASSIFIER TRAINING
        #
        u = self.classifier

        X_train_, X_train_ids = A_train.to_array()
        X_train_ = X_train_[:, :, :, 0].astype(np.float32)

        y_train_, y_train_ids = A_train.to_array()
        y_train_ = y_train_[:, :, :, 1].astype(np.float32)

        X_val_, X_val_ids = A_val.to_array()
        X_val_ = X_val_[:, :, :, 0].astype(np.float32)

        y_val_, y_val_ids = A_val.to_array()
        y_val_ = y_val_[:, :, :, 1].astype(np.float32)

        history = u.train(X_train_, y_train_, X_val_, y_val_,
                          patience_counter=patience_counter)

        X_test_, X_test_ids = A_test.to_array()
        X_test__ = X_test_[:, :, :, 0].astype(np.float32)
        y_test_ = X_test_[:, :, :, 1].astype(np.float32)

        print(&#39;Testing the classifier...&#39;)
        predictions, scores = u.predict(X_test__, y_test_)

        #
        # A_TEST PREDICTION
        #
        A_test_pred = Collection.from_list(predictions, X_test_ids)

        M.register(A_test_pred, &#39;A_test_pred&#39;)

        self.classifier_scores.append(scores)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step1.pickle&#39;))

    #
    # STEP 2 (gets called by 4)
    #
    def create_C_dataset(self):
        &#34;&#34;&#34; Create the C dataset from the classifier predictions (internal!).&#34;&#34;&#34;
        M = self.M

        A_test = M.get(&#39;A_test&#39;)
        A_test_pred = M.get(&#39;A_test_pred&#39;)
        B = M.get(&#39;B&#39;)

        A_test_images_only_, A_test_images_only_ids = A_test.to_array()
        A_test_images_only_ = A_test_images_only_[:, :, :, 0].astype(np.uint8)

        A_test_pred_, A_test_pred_ids = A_test_pred.to_array()
        A_test_pred_ = A_test_pred_.astype(np.uint8)

        A_test_with_pred_ = np.stack(
            (A_test_images_only_, A_test_pred_[:, :, :, 0]), axis=-1)

        #
        # CREATE C DATASET
        #
        B_, B_ids = B.to_array()

        C_size = (2 * B_.shape[0], B_.shape[1], B_.shape[2])
        C_images_ = np.zeros((C_size + (B_.shape[3],)), dtype=B_.dtype)

        C_images_[0:A_test_with_pred_.shape[0]] = A_test_with_pred_
        C_images_[A_test_with_pred_.shape[0]:] = B_

        C_labels_ = np.empty((C_size + (1,)), dtype=np.bool)
        C_labels_[0:B_.shape[0], 0, 0, 0] = 1
        C_labels_[B_.shape[0]:, 0, 0, 0] = 0

        C_ = np.concatenate((C_images_, C_labels_), axis=-1)

        # combine the uniq ids from A_test_pred and B
        C_ids = A_test_pred_ids + B_ids

        C = Collection.from_list(C_, C_ids)

        M.register(C, &#39;C&#39;)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step2.pickle&#39;))

    #
    # STEP 3 (gets called by 4)
    #
    def create_C_train_val_test_split(self,
                                      train_count=300,
                                      val_count=100,
                                      test_count=100):
        &#34;&#34;&#34; Create the C train/val/test split from the C dataset (internal!).
        Parameters
        ----------
        train_count : int
            Number of training samples.
        val_count : int
            Number of validation samples.
        test_count : int
            Number of test samples.
        Returns
        -------
        None
        &#34;&#34;&#34;

        M = self.M

        C = M.get(&#39;C&#39;)
        # we need to shuffle in connection land to keep track of the ids
        C.shuffle()

        C_, C_ids = C.to_array()
        C_train_, C_val_, C_test_ = Util.create_train_val_test_split(
            C_, train_count=train_count, val_count=val_count,
            test_count=test_count, shuffle=False)

        C_train_ids = C_ids[0:train_count]
        C_val_ids = C_ids[train_count:train_count + val_count]
        C_test_ids = \
            C_ids[train_count + val_count:train_count + val_count + test_count]

        C_train = Collection.from_list(C_train_, C_train_ids)
        C_val = Collection.from_list(C_val_, C_val_ids)
        C_test = Collection.from_list(C_test_, C_test_ids)

        M.register(C_train, &#39;C_train&#39;)
        M.register(C_val, &#39;C_val&#39;)
        M.register(C_test, &#39;C_test&#39;)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step3.pickle&#39;))

    #
    # STEP 4 (calls 2+3+5)
    #
    def run_discriminator(self, train_ratio=0.4, val_ratio=0.1, test_ratio=0.5,
                          threshold=1e-6):
        &#34;&#34;&#34; Train the discriminator using C_train/C_val. If the discriminator was
        trained, this will just predict.
        Parameters
        ----------
        train_ratio : float
            Ratio of training samples.
        val_ratio : float
            Ratio of validation samples.
        test_ratio : float
            Ratio of test samples.
        threshold : float
            Threshold for the sum of train_ratio, val_ratio, and test_ratio.
        Returns
        -------
        None
        &#34;&#34;&#34;
        # Check that the sum of the ratios is approximately equal to 1
        if not (
                1 - threshold &lt;= train_ratio + val_ratio + test_ratio &lt;= 1 + threshold):
            raise ValueError(
                &#34;The sum of train_ratio, val_ratio, and test_ratio must be approximately equal to 1&#34;)

        self.create_C_dataset()

        dataset_size = self.dataset_size
        weights = self.weights

        train_count = int(0.2 * train_ratio * dataset_size)
        val_count = int(0.2 * val_ratio * dataset_size)
        test_count = int(0.2 * test_ratio * dataset_size)

        if weights:
            train_count = int(weights[&#39;B&#39;] * weights[&#39;B_train&#39;] * dataset_size)
            val_count = int(weights[&#39;B&#39;] * weights[&#39;B_val&#39;] * dataset_size)
            test_count = int(weights[&#39;B&#39;] * weights[&#39;B_test&#39;] * dataset_size)

        self.create_C_train_val_test_split(train_count, val_count, test_count)

        M = self.M

        cnnd = self.discriminator

        C_train = M.get(&#39;C_train&#39;)
        C_val = M.get(&#39;C_val&#39;)

        C_train_, C_train_ids = C_train.to_array()
        X_train_images_ = C_train_[:, :, :, 0]
        X_train_masks_ = C_train_[:, :, :, 1]
        y_train_ = C_train_[:, 0, 0, 2]

        C_val_, C_val_ids = C_val.to_array()
        X_val_images_ = C_val_[:, :, :, 0]
        X_val_masks_ = C_val_[:, :, :, 1]
        y_val_ = C_val_[:, 0, 0, 2]

        cnnd.train(X_train_images_, X_train_masks_, y_train_, X_val_images_,
                   X_val_masks_, y_val_)
        self.discriminator = cnnd

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step4.pickle&#39;))

        self.predict_discriminator()

    #
    # STEP 5 (gets called by 4)
    #
    def predict_discriminator(self):
        &#34;&#34;&#34; Predict using the Discriminator (internal!) &#34;&#34;&#34;
        M = self.M

        C_test = M.get(&#39;C_test&#39;)
        C_test_, C_test_ids = C_test.to_array()
        X_test_images_ = C_test_[:, :, :, 0]
        X_test_masks_ = C_test_[:, :, :, 1]
        y_test_ = C_test_[:, 0, 0, 2]

        cnnd = self.discriminator
        print(&#39;Testing the discriminator...&#39;)
        predictions, scores = cnnd.predict(X_test_images_, X_test_masks_,
                                           y_test_)

        self.discriminator_scores.append(scores)

        C_test_pred = Collection.from_list(predictions, C_test_ids)

        M.register(C_test_pred, &#39;C_test_pred&#39;)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step5.pickle&#39;))

    #
    # STEP 6
    #
    def find_machine_labels(self):
        &#34;&#34;&#34; This finds all machine labels, as indicated from the Discriminator
        and create dataset D.  Returns number of machine labels found.
        &#34;&#34;&#34;
        M = self.M

        C_test = M.get(&#39;C_test&#39;)
        C_test_pred = M.get(&#39;C_test_pred&#39;)

        C_test_, C_test_ids = C_test.to_array()
        C_test_pred_, C_test_pred_ids = C_test_pred.to_array()

        all_machine_labels_indices = np.where(C_test_pred_ == 1)[0]

        assert (C_test_ids == C_test_pred_ids)  # must be the same

        #
        # CREATE D DATASET
        #
        D_ = np.empty(((len(all_machine_labels_indices),) + C_test_.shape[1:]),
                      dtype=C_test_.dtype)
        D_ids = []

        for i, p in enumerate(all_machine_labels_indices):
            D_[i] = C_test_[p]
            D_ids.append(C_test_ids[p])

        if len(all_machine_labels_indices) == 0:
            print(&#39;No machine labels found. Skipping step 6.&#39;)
            return 0

        assert (np.all(
            D_[0] == C_test_[all_machine_labels_indices[0]]))  # quick check

        assert (D_ids[1] == C_test_ids[all_machine_labels_indices[1]])

        D = Collection.from_list(D_, D_ids)

        M.register(D, &#39;D&#39;)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step6.pickle&#39;))

        return len(all_machine_labels_indices)

    #
    # STEP 7 (calls 8)
    #
    def relabel(self, percent_to_replace=30):
        &#34;&#34;&#34; Relabels a subset of Dataset D
        Parameters
        ----------
        percent_to_replace : int
            Percentage of D to relabel
        Returns
        -------
        None
        &#34;&#34;&#34;

        M = self.M

        D = M.get(&#39;D&#39;)

        # check that D in not NoneType
        if D is None:
            print(
                &#39;D is empty. Dataset may be too complex for this method. Skipping step 7.&#39;)
            return

        D_, D_ids = D.to_array()
        # TODO: Check why these are here if not used
        D_images = D_[:, :, :, 0]
        D_masks = D_[:, :, :, 1]
        D_labels = D_[:, 0, 0, 2]

        selected_ids = list(np.random.choice(D_ids, len(D_ids) // int(
            100 / percent_to_replace), replace=False))

        print(&#39;Replacing&#39;, len(selected_ids), &#39;from&#39;, len(D_ids), &#39;!&#39;)

        D_relabeled_ = np.empty((len(selected_ids),) + D_.shape[1:],
                                dtype=D_.dtype)

        A_test = M.get(&#39;A_test&#39;)
        B = M.get(&#39;B&#39;)

        uniqids_in_D = list(D.data.keys())

        for i, k in enumerate(selected_ids):
            # i is running number 0..len(selected_ids)
            # k is the uniqid of a datapoint

            # j is the position of the uniqid in D
            j = uniqids_in_D.index(k)

            # grab image
            image = D_[j, :, :, 0]
            label = D_[j, 0, 0, 2]

            origin = &#39;&#39;
            if k in A_test.data:
                origin = &#39;A_test&#39;
            elif k in B.data:
                origin = &#39;B&#39;
            else:
                print(&#39;Lost Datapoint!!&#39;, k)
                continue

            ### SIMULATION CASE -&gt; just grab ground truth###
            ### OTHERWISE THIS IS THE ENTRYPOINT FOR MANUAL RE-LABELING ###
            relabeled = M.get(origin).data[k][:, :, 1]

            D_relabeled_[i, :, :, 0] = image
            D_relabeled_[i, :, :, 1] = relabeled
            D_relabeled_[i, 0, 0, 2] = label

        print(&#39;D_relabeled_&#39;, D_relabeled_.shape[0])

        D_relabeled = Collection.from_list(D_relabeled_, selected_ids)

        M.register(D_relabeled, &#39;D_relabeled&#39;)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step7.pickle&#39;))

        self.update_A_train()

    #
    # STEP 8
    #
    def update_A_train(self, balance=True, fillup=True):
        &#34;&#34;&#34; Update A_train with selected points from D. Then, remove D from B
        and A_test (wherever it was!). Fill-up both B and A_test (internal!).
        Parameters
        ----------
        balance : bool
            If True, balance A_train with B and A_test
        fillup : bool
            If True, fill-up B and A_test with points from A_train
        Returns
        -------
        None
        &#34;&#34;&#34;
        M = self.M

        D_relabeled = M.get(&#39;D_relabeled&#39;)

        A_train = M.get(&#39;A_train&#39;)
        A_test = M.get(&#39;A_test&#39;)
        B = M.get(&#39;B&#39;)

        Z = M.get(&#39;Z&#39;)  # repository

        removed_counter = 0
        filled_counter = 0

        point_ids = list(D_relabeled.data.keys())

        print(&#39;point ids&#39;, len(point_ids))

        # Move points from A_test to A_train
        for k in point_ids:
            # we need to check where this datapoint originally came from
            if (k in A_test.data):
                origintext = &#39;A_test&#39;
                origin = A_test
            elif (k in B.data):
                origintext = &#39;B&#39;
                origin = B
            else:
                print(&#39;Lost Datapoint!!&#39;, k)
                continue

            p = Point(origin.data[k])
            p.id = k

            M.remove_and_add(origin, A_train, p)
            removed_counter += 1

            # now fill up the origin from Z
            if fillup:
                Z_uniq_ids = list(Z.data.keys())
                Z_uniq_id = np.random.choice(Z_uniq_ids, replace=False)

                p = Point(Z.data[Z_uniq_id])
                p.id = Z_uniq_id

                M.remove_and_add(Z, origin, p)
                filled_counter += 1

        print(&#39;Removed:&#39;, removed_counter, &#39;Filled:&#39;, filled_counter)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step8.pickle&#39;))

    def run(self,
            images,
            masks,
            weights,
            runs=1,
            patience_counter=2,
            percent_to_replace=30):
        # assert that len of images and masks is the same
        assert len(images) == len(masks)
        dataset_size = len(images)
        self.setup_data(images=images, masks=masks,
                        dataset_size=dataset_size,
                        weights=weights)

        for run in range(runs):
            print(&#39;******&#39;)
            print(&#39;Loop&#39;, run)
            t0 = time.time()
            self.run_classifier(patience_counter=patience_counter)
            self.run_discriminator()
            l = self.find_machine_labels()
            if l == 0:
                print(&#39;No more machine labels.&#39;)
                print(&#39;TOOK&#39;, time.time() - t0, &#39;seconds&#39;)
                break
            self.relabel(percent_to_replace=percent_to_replace)
            print(&#39;TOOK&#39;, time.time() - t0, &#39;seconds&#39;)
            print(&#39;==== DONE LOOP&#39;, run, &#39;====&#39;)

    #
    # PLOT!
    #
    def plot(self):

        x = range(len(self.classifier_scores))
        y1 = [v[1] for v in self.classifier_scores]
        y2 = [v[1] for v in self.discriminator_scores]

        Util.plot_accuracies(x, y1, y2)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="gp2.runner.validate_weights"><code class="name flex">
<span>def <span class="ident">validate_weights</span></span>(<span>weights, tolerance=1e-06)</span>
</code></dt>
<dd>
<div class="desc"><p>Validate the weights for training.
What must be verified:
A_train + A_val + A_test = 1. </p>
<pre><code>B_train + B_val + B_test = 1.

A + B + Z = 1.

A * A_test = B.

Z &gt; .1.
</code></pre>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>weights</code></strong> :&ensp;<code>dict</code></dt>
<dd>Weights to use for training. If None, will use the default weights.
Weights should be a dictionary with keys containing the following:
'A_train', 'A_val', 'A_test', 'B_train','B_val', 'B_test', 'A', 'B',
'Z'</dd>
<dt><strong><code>tolerance</code></strong> :&ensp;<code>float</code></dt>
<dd>Tolerance to use for the validation.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>None</code></strong> :&ensp;<code>None</code></dt>
<dd>If the weights are valid, will return None.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the weights are not valid.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validate_weights(weights, tolerance=1e-6):
    &#34;&#34;&#34; Validate the weights for training.
    What must be verified:
        A_train + A_val + A_test = 1. \n
        B_train + B_val + B_test = 1. \n
        A + B + Z = 1. \n
        A * A_test = B. \n
        Z &gt; .1.
    Parameters
    ----------
    weights : dict
        Weights to use for training. If None, will use the default weights.
        Weights should be a dictionary with keys containing the following:
        &#39;A_train&#39;, &#39;A_val&#39;, &#39;A_test&#39;, &#39;B_train&#39;,&#39;B_val&#39;, &#39;B_test&#39;, &#39;A&#39;, &#39;B&#39;,
        &#39;Z&#39;
    tolerance : float
        Tolerance to use for the validation.
    Returns
    -------
    None : None
        If the weights are valid, will return None.
    Raises
    ------
    ValueError
        If the weights are not valid.
    &#34;&#34;&#34;
    # Check if A_train + A_val + A_test = 1
    A_sum = weights[&#39;A_train&#39;] + weights[&#39;A_val&#39;] + weights[&#39;A_test&#39;]
    if not np.isclose(A_sum, 1, rtol=tolerance):
        raise ValueError(&#34;A_train + A_val + A_test must be equal to 1&#34;)

    # Check if B_train + B_val + B_test = 1
    B_sum = weights[&#39;B_train&#39;] + weights[&#39;B_val&#39;] + weights[&#39;B_test&#39;]
    if not np.isclose(B_sum, 1, rtol=tolerance):
        raise ValueError(&#34;B_train + B_val + B_test must be equal to 1&#34;)

    # Check if A + B + Z = 1
    main_sum = weights[&#39;A&#39;] + weights[&#39;B&#39;] + weights[&#39;Z&#39;]
    if not np.isclose(main_sum, 1, rtol=tolerance):
        raise ValueError(&#34;A + B + Z must be equal to 1&#34;)

    # Check if A * A_test = B
    A_mul_A_test = weights[&#39;A&#39;] * weights[&#39;A_test&#39;]
    if not np.isclose(A_mul_A_test, weights[&#39;B&#39;], rtol=tolerance):
        raise ValueError(&#34;A * A_test must be equal to B&#34;)

    # Check if Z &gt; .1
    if weights[&#39;Z&#39;] &lt; .1:
        raise ValueError(&#34;Z must be greater than .1&#34;)

    print(&#34;Weights OK!&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="gp2.runner.Runner"><code class="flex name class">
<span>class <span class="ident">Runner</span></span>
<span>(</span><span>verbose=False, workingdir='/tmp/tmpv6c9olasGP2', store_after_each_step=False, classifier=None, discriminator=None, weights=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Initialize the GP2 runner with specified classifier and
discriminator.
Parameters</p>
<hr>
<dl>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, will print out additional information during training.</dd>
<dt><strong><code>workingdir</code></strong> :&ensp;<code>str</code></dt>
<dd>Location where to store temporary files and model checkpoints.</dd>
<dt><strong><code>store_after_each_step</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, will store the model after each step of the training
process.</dd>
<dt><strong><code>classifier</code></strong> :&ensp;<code>str</code> or <code>Classifier</code></dt>
<dd>The classifier to use. If None or 'unet', will use the default
handcrafted
unet classifier. Supported classifiers are:
'unet','unetplus', 'kattunet2d', 'kunet2d', 'kunetplus2d',
'kresunet2d', 'kunet3plus2d', 'kvnet2d', 'kr2unet2d'</dd>
<dt><strong><code>discriminator</code></strong> :&ensp;<code>str</code> or <code>Discriminator</code></dt>
<dd>The discriminator to use. If None or 'cnn', will use the default
handcrafted cnn discriminator.</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Additional keyword arguments to pass to the classifier and
discriminator.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Runner:

    def __init__(self,
                 verbose=False,
                 workingdir=tempfile.mkdtemp(suffix=&#39;GP2&#39;),
                 store_after_each_step=False,
                 classifier=None,
                 discriminator=None,
                 weights=None,
                 **kwargs):
        &#34;&#34;&#34; Initialize the GP2 runner with specified classifier and
        discriminator.
        Parameters
        ----------
        verbose : bool
            If True, will print out additional information during training.
        workingdir : str
            Location where to store temporary files and model checkpoints.
        store_after_each_step : bool
            If True, will store the model after each step of the training
            process.
        classifier : str or Classifier
            The classifier to use. If None or &#39;unet&#39;, will use the default
            handcrafted  unet classifier. Supported classifiers are:
            &#39;unet&#39;,&#39;unetplus&#39;, &#39;kattunet2d&#39;, &#39;kunet2d&#39;, &#39;kunetplus2d&#39;,
            &#39;kresunet2d&#39;, &#39;kunet3plus2d&#39;, &#39;kvnet2d&#39;, &#39;kr2unet2d&#39;
        discriminator : str or Discriminator
            The discriminator to use. If None or &#39;cnn&#39;, will use the default
            handcrafted cnn discriminator.
        **kwargs : dict
            Additional keyword arguments to pass to the classifier and
            discriminator.
        &#34;&#34;&#34;

        self.weights = weights
        self.store_after_each_step = store_after_each_step

        self.workingdir = workingdir

        self.verbose = verbose

        self.M = Manager()

        self.dataset_size = None

        # Initialize the classifier
        self.classifier_scores = []
        if classifier is None or isinstance(classifier,
                                            UNet) or classifier == &#39;unet&#39;:
            self.classifier = UNet(verbose=self.verbose,
                                   workingdir=self.workingdir)
        elif isinstance(classifier, KUNet) or classifier == &#39;kvanillaunet&#39;:
            self.classifier = KUNet(verbose=self.verbose,
                                    workingdir=self.workingdir,
                                    **kwargs)
        elif isinstance(classifier, UNetPLUS) or classifier == &#39;unetplus&#39;:
            self.classifier = UNetPLUS(verbose=self.verbose,
                                       workingdir=self.workingdir, **kwargs)
        elif isinstance(classifier, KATTUnet2D) or classifier == &#39;kattunet2d&#39;:
            self.classifier = KATTUnet2D(verbose=self.verbose,
                                         workingdir=self.workingdir,
                                         **kwargs)
        elif isinstance(classifier, KUNet2D) or classifier == &#39;kunet2d&#39;:
            self.classifier = KUNet2D(verbose=self.verbose,
                                      workingdir=self.workingdir, **kwargs)
        elif isinstance(classifier, KUNetPlus2D) or classifier == &#39;kunetplus2d&#39;:
            self.classifier = KUNetPlus2D(verbose=self.verbose,
                                          workingdir=self.workingdir,
                                          **kwargs)
        elif isinstance(classifier, KResUNet2D) or classifier == &#39;kresunet2d&#39;:
            self.classifier = KResUNet2D(verbose=self.verbose,
                                         workingdir=self.workingdir,
                                         **kwargs)
        elif isinstance(classifier,
                        KUNet3Plus2D) or classifier == &#39;kunet3plus2d&#39;:
            self.classifier = KUNet3Plus2D(verbose=self.verbose,
                                           workingdir=self.workingdir,
                                           **kwargs)
        elif isinstance(classifier, KVNet2D) or classifier == &#39;kvnet2d&#39;:
            self.classifier = KVNet2D(verbose=self.verbose,
                                      workingdir=self.workingdir, **kwargs)
        elif isinstance(classifier, KR2UNet2dD) or classifier == &#39;kr2unet2d&#39;:
            self.classifier = KR2UNet2dD(verbose=self.verbose,
                                         workingdir=self.workingdir,
                                         **kwargs)
        else:
            raise ValueError(&#39;Classifier not supported: {}&#39;.format(classifier))

        # Initialize the discriminator
        self.discriminator_scores = []
        if discriminator is None or isinstance(
                discriminator, CNNDiscriminator) or discriminator == &#39;cnn&#39;:
            print(&#39;Using default discriminator (CNN)&#39;)
            self.discriminator = CNNDiscriminator(
                verbose=self.verbose, workingdir=self.workingdir)
        elif isinstance(discriminator,
                        CNNDiscriminatorPLUS) or discriminator == &#39;cnnplus&#39;:
            print(&#39;Using  discriminator (CNN+)&#39;)
            self.discriminator = CNNDiscriminatorPLUS(
                verbose=self.verbose, workingdir=self.workingdir)
        else:
            raise ValueError(&#39;Discriminator not supported: {}&#39;.format(
                discriminator))

    #
    # STEP 0
    #
    def setup_data(self, images, masks, dataset_size=1000, weights=None):
        &#34;&#34;&#34; Set up the data for training.
        Each dataset is composed of three parts:
            A_: data to train/val/test the classifier \n
            B_: expert labels to feed directly into the discriminator \n
            Z_: a repository of additional data that can further train the
            classifier
        Parameters
        ----------
        images : list of np.ndarray
            List of images to use for training.
        masks : list of np.ndarray
            List of masks to use for training.
        dataset_size : int
            Number of images to use for training.
        weights : dict
            Weights to use for training. If None, will use the default weights.
            Weights should be a dictionary with keys &#39;A&#39;, &#39;B&#39;, &#39;Z&#39;, &#39;A_test&#39;.
            The weights should sum to 1.0.
        Returns
        -------
        None
        &#34;&#34;&#34;
        M = self.M

        self.dataset_size = dataset_size
        self.weights = weights

        if weights:
            validate_weights(weights)

        A_, B_, Z_ = Util.create_A_B_Z_split(images, masks,
                                             dataset_size=dataset_size,
                                             weights=weights)

        A = Collection.from_list(A_)
        B = Collection.from_list(B_)
        Z = Collection.from_list(Z_)

        M.register(A, &#39;A&#39;)  # we might not need to save this one here
        M.register(B, &#39;B&#39;)
        M.register(Z, &#39;Z&#39;)

        A = M.get(&#39;A&#39;)
        A_, A_ids = A.to_array()

        # if no weights configured, fallback
        train_count = int(0.4 * 0.1 * dataset_size)
        val_count = int(0.4 * 0.4 * dataset_size)
        test_count = int(0.4 * 0.5 * dataset_size)

        if weights:
            train_count = int(weights[&#39;A&#39;] * weights[&#39;A_train&#39;] * dataset_size)
            val_count = int(weights[&#39;A&#39;] * weights[&#39;A_val&#39;] * dataset_size)
            test_count = int(weights[&#39;A&#39;] * weights[&#39;A_test&#39;] * dataset_size)

        A_train_, A_val_, A_test_ = Util.create_train_val_test_split(
            A_, train_count=train_count, val_count=val_count,
            test_count=test_count, shuffle=False)
        A_train_ids = A_ids[0:train_count]
        A_val_ids = A_ids[train_count:train_count + val_count]
        A_test_ids = A_ids[
                     train_count + val_count:train_count + val_count + test_count]

        A_train = Collection.from_list(A_train_, A_train_ids)  # COLLECTION LAND
        A_val = Collection.from_list(A_val_, A_val_ids)
        A_test = Collection.from_list(A_test_, A_test_ids)

        M.register(A_train, &#39;A_train&#39;)
        M.register(A_val, &#39;A_val&#39;)
        M.register(A_test, &#39;A_test&#39;)

    #
    # STEP 1
    #
    def run_classifier(self, patience_counter=2):
        &#34;&#34;&#34; (Re-)Train the classifier.
        Parameters
        ----------
        patience_counter : int
            Number of epochs to wait before early stopping.
        Returns
        -------
        None
        &#34;&#34;&#34;
        M = self.M

        A_train = M.get(&#39;A_train&#39;)
        A_val = M.get(&#39;A_val&#39;)
        A_test = M.get(&#39;A_test&#39;)

        #
        # ACTUAL CLASSIFIER TRAINING
        #
        u = self.classifier

        X_train_, X_train_ids = A_train.to_array()
        X_train_ = X_train_[:, :, :, 0].astype(np.float32)

        y_train_, y_train_ids = A_train.to_array()
        y_train_ = y_train_[:, :, :, 1].astype(np.float32)

        X_val_, X_val_ids = A_val.to_array()
        X_val_ = X_val_[:, :, :, 0].astype(np.float32)

        y_val_, y_val_ids = A_val.to_array()
        y_val_ = y_val_[:, :, :, 1].astype(np.float32)

        history = u.train(X_train_, y_train_, X_val_, y_val_,
                          patience_counter=patience_counter)

        X_test_, X_test_ids = A_test.to_array()
        X_test__ = X_test_[:, :, :, 0].astype(np.float32)
        y_test_ = X_test_[:, :, :, 1].astype(np.float32)

        print(&#39;Testing the classifier...&#39;)
        predictions, scores = u.predict(X_test__, y_test_)

        #
        # A_TEST PREDICTION
        #
        A_test_pred = Collection.from_list(predictions, X_test_ids)

        M.register(A_test_pred, &#39;A_test_pred&#39;)

        self.classifier_scores.append(scores)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step1.pickle&#39;))

    #
    # STEP 2 (gets called by 4)
    #
    def create_C_dataset(self):
        &#34;&#34;&#34; Create the C dataset from the classifier predictions (internal!).&#34;&#34;&#34;
        M = self.M

        A_test = M.get(&#39;A_test&#39;)
        A_test_pred = M.get(&#39;A_test_pred&#39;)
        B = M.get(&#39;B&#39;)

        A_test_images_only_, A_test_images_only_ids = A_test.to_array()
        A_test_images_only_ = A_test_images_only_[:, :, :, 0].astype(np.uint8)

        A_test_pred_, A_test_pred_ids = A_test_pred.to_array()
        A_test_pred_ = A_test_pred_.astype(np.uint8)

        A_test_with_pred_ = np.stack(
            (A_test_images_only_, A_test_pred_[:, :, :, 0]), axis=-1)

        #
        # CREATE C DATASET
        #
        B_, B_ids = B.to_array()

        C_size = (2 * B_.shape[0], B_.shape[1], B_.shape[2])
        C_images_ = np.zeros((C_size + (B_.shape[3],)), dtype=B_.dtype)

        C_images_[0:A_test_with_pred_.shape[0]] = A_test_with_pred_
        C_images_[A_test_with_pred_.shape[0]:] = B_

        C_labels_ = np.empty((C_size + (1,)), dtype=np.bool)
        C_labels_[0:B_.shape[0], 0, 0, 0] = 1
        C_labels_[B_.shape[0]:, 0, 0, 0] = 0

        C_ = np.concatenate((C_images_, C_labels_), axis=-1)

        # combine the uniq ids from A_test_pred and B
        C_ids = A_test_pred_ids + B_ids

        C = Collection.from_list(C_, C_ids)

        M.register(C, &#39;C&#39;)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step2.pickle&#39;))

    #
    # STEP 3 (gets called by 4)
    #
    def create_C_train_val_test_split(self,
                                      train_count=300,
                                      val_count=100,
                                      test_count=100):
        &#34;&#34;&#34; Create the C train/val/test split from the C dataset (internal!).
        Parameters
        ----------
        train_count : int
            Number of training samples.
        val_count : int
            Number of validation samples.
        test_count : int
            Number of test samples.
        Returns
        -------
        None
        &#34;&#34;&#34;

        M = self.M

        C = M.get(&#39;C&#39;)
        # we need to shuffle in connection land to keep track of the ids
        C.shuffle()

        C_, C_ids = C.to_array()
        C_train_, C_val_, C_test_ = Util.create_train_val_test_split(
            C_, train_count=train_count, val_count=val_count,
            test_count=test_count, shuffle=False)

        C_train_ids = C_ids[0:train_count]
        C_val_ids = C_ids[train_count:train_count + val_count]
        C_test_ids = \
            C_ids[train_count + val_count:train_count + val_count + test_count]

        C_train = Collection.from_list(C_train_, C_train_ids)
        C_val = Collection.from_list(C_val_, C_val_ids)
        C_test = Collection.from_list(C_test_, C_test_ids)

        M.register(C_train, &#39;C_train&#39;)
        M.register(C_val, &#39;C_val&#39;)
        M.register(C_test, &#39;C_test&#39;)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step3.pickle&#39;))

    #
    # STEP 4 (calls 2+3+5)
    #
    def run_discriminator(self, train_ratio=0.4, val_ratio=0.1, test_ratio=0.5,
                          threshold=1e-6):
        &#34;&#34;&#34; Train the discriminator using C_train/C_val. If the discriminator was
        trained, this will just predict.
        Parameters
        ----------
        train_ratio : float
            Ratio of training samples.
        val_ratio : float
            Ratio of validation samples.
        test_ratio : float
            Ratio of test samples.
        threshold : float
            Threshold for the sum of train_ratio, val_ratio, and test_ratio.
        Returns
        -------
        None
        &#34;&#34;&#34;
        # Check that the sum of the ratios is approximately equal to 1
        if not (
                1 - threshold &lt;= train_ratio + val_ratio + test_ratio &lt;= 1 + threshold):
            raise ValueError(
                &#34;The sum of train_ratio, val_ratio, and test_ratio must be approximately equal to 1&#34;)

        self.create_C_dataset()

        dataset_size = self.dataset_size
        weights = self.weights

        train_count = int(0.2 * train_ratio * dataset_size)
        val_count = int(0.2 * val_ratio * dataset_size)
        test_count = int(0.2 * test_ratio * dataset_size)

        if weights:
            train_count = int(weights[&#39;B&#39;] * weights[&#39;B_train&#39;] * dataset_size)
            val_count = int(weights[&#39;B&#39;] * weights[&#39;B_val&#39;] * dataset_size)
            test_count = int(weights[&#39;B&#39;] * weights[&#39;B_test&#39;] * dataset_size)

        self.create_C_train_val_test_split(train_count, val_count, test_count)

        M = self.M

        cnnd = self.discriminator

        C_train = M.get(&#39;C_train&#39;)
        C_val = M.get(&#39;C_val&#39;)

        C_train_, C_train_ids = C_train.to_array()
        X_train_images_ = C_train_[:, :, :, 0]
        X_train_masks_ = C_train_[:, :, :, 1]
        y_train_ = C_train_[:, 0, 0, 2]

        C_val_, C_val_ids = C_val.to_array()
        X_val_images_ = C_val_[:, :, :, 0]
        X_val_masks_ = C_val_[:, :, :, 1]
        y_val_ = C_val_[:, 0, 0, 2]

        cnnd.train(X_train_images_, X_train_masks_, y_train_, X_val_images_,
                   X_val_masks_, y_val_)
        self.discriminator = cnnd

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step4.pickle&#39;))

        self.predict_discriminator()

    #
    # STEP 5 (gets called by 4)
    #
    def predict_discriminator(self):
        &#34;&#34;&#34; Predict using the Discriminator (internal!) &#34;&#34;&#34;
        M = self.M

        C_test = M.get(&#39;C_test&#39;)
        C_test_, C_test_ids = C_test.to_array()
        X_test_images_ = C_test_[:, :, :, 0]
        X_test_masks_ = C_test_[:, :, :, 1]
        y_test_ = C_test_[:, 0, 0, 2]

        cnnd = self.discriminator
        print(&#39;Testing the discriminator...&#39;)
        predictions, scores = cnnd.predict(X_test_images_, X_test_masks_,
                                           y_test_)

        self.discriminator_scores.append(scores)

        C_test_pred = Collection.from_list(predictions, C_test_ids)

        M.register(C_test_pred, &#39;C_test_pred&#39;)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step5.pickle&#39;))

    #
    # STEP 6
    #
    def find_machine_labels(self):
        &#34;&#34;&#34; This finds all machine labels, as indicated from the Discriminator
        and create dataset D.  Returns number of machine labels found.
        &#34;&#34;&#34;
        M = self.M

        C_test = M.get(&#39;C_test&#39;)
        C_test_pred = M.get(&#39;C_test_pred&#39;)

        C_test_, C_test_ids = C_test.to_array()
        C_test_pred_, C_test_pred_ids = C_test_pred.to_array()

        all_machine_labels_indices = np.where(C_test_pred_ == 1)[0]

        assert (C_test_ids == C_test_pred_ids)  # must be the same

        #
        # CREATE D DATASET
        #
        D_ = np.empty(((len(all_machine_labels_indices),) + C_test_.shape[1:]),
                      dtype=C_test_.dtype)
        D_ids = []

        for i, p in enumerate(all_machine_labels_indices):
            D_[i] = C_test_[p]
            D_ids.append(C_test_ids[p])

        if len(all_machine_labels_indices) == 0:
            print(&#39;No machine labels found. Skipping step 6.&#39;)
            return 0

        assert (np.all(
            D_[0] == C_test_[all_machine_labels_indices[0]]))  # quick check

        assert (D_ids[1] == C_test_ids[all_machine_labels_indices[1]])

        D = Collection.from_list(D_, D_ids)

        M.register(D, &#39;D&#39;)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step6.pickle&#39;))

        return len(all_machine_labels_indices)

    #
    # STEP 7 (calls 8)
    #
    def relabel(self, percent_to_replace=30):
        &#34;&#34;&#34; Relabels a subset of Dataset D
        Parameters
        ----------
        percent_to_replace : int
            Percentage of D to relabel
        Returns
        -------
        None
        &#34;&#34;&#34;

        M = self.M

        D = M.get(&#39;D&#39;)

        # check that D in not NoneType
        if D is None:
            print(
                &#39;D is empty. Dataset may be too complex for this method. Skipping step 7.&#39;)
            return

        D_, D_ids = D.to_array()
        # TODO: Check why these are here if not used
        D_images = D_[:, :, :, 0]
        D_masks = D_[:, :, :, 1]
        D_labels = D_[:, 0, 0, 2]

        selected_ids = list(np.random.choice(D_ids, len(D_ids) // int(
            100 / percent_to_replace), replace=False))

        print(&#39;Replacing&#39;, len(selected_ids), &#39;from&#39;, len(D_ids), &#39;!&#39;)

        D_relabeled_ = np.empty((len(selected_ids),) + D_.shape[1:],
                                dtype=D_.dtype)

        A_test = M.get(&#39;A_test&#39;)
        B = M.get(&#39;B&#39;)

        uniqids_in_D = list(D.data.keys())

        for i, k in enumerate(selected_ids):
            # i is running number 0..len(selected_ids)
            # k is the uniqid of a datapoint

            # j is the position of the uniqid in D
            j = uniqids_in_D.index(k)

            # grab image
            image = D_[j, :, :, 0]
            label = D_[j, 0, 0, 2]

            origin = &#39;&#39;
            if k in A_test.data:
                origin = &#39;A_test&#39;
            elif k in B.data:
                origin = &#39;B&#39;
            else:
                print(&#39;Lost Datapoint!!&#39;, k)
                continue

            ### SIMULATION CASE -&gt; just grab ground truth###
            ### OTHERWISE THIS IS THE ENTRYPOINT FOR MANUAL RE-LABELING ###
            relabeled = M.get(origin).data[k][:, :, 1]

            D_relabeled_[i, :, :, 0] = image
            D_relabeled_[i, :, :, 1] = relabeled
            D_relabeled_[i, 0, 0, 2] = label

        print(&#39;D_relabeled_&#39;, D_relabeled_.shape[0])

        D_relabeled = Collection.from_list(D_relabeled_, selected_ids)

        M.register(D_relabeled, &#39;D_relabeled&#39;)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step7.pickle&#39;))

        self.update_A_train()

    #
    # STEP 8
    #
    def update_A_train(self, balance=True, fillup=True):
        &#34;&#34;&#34; Update A_train with selected points from D. Then, remove D from B
        and A_test (wherever it was!). Fill-up both B and A_test (internal!).
        Parameters
        ----------
        balance : bool
            If True, balance A_train with B and A_test
        fillup : bool
            If True, fill-up B and A_test with points from A_train
        Returns
        -------
        None
        &#34;&#34;&#34;
        M = self.M

        D_relabeled = M.get(&#39;D_relabeled&#39;)

        A_train = M.get(&#39;A_train&#39;)
        A_test = M.get(&#39;A_test&#39;)
        B = M.get(&#39;B&#39;)

        Z = M.get(&#39;Z&#39;)  # repository

        removed_counter = 0
        filled_counter = 0

        point_ids = list(D_relabeled.data.keys())

        print(&#39;point ids&#39;, len(point_ids))

        # Move points from A_test to A_train
        for k in point_ids:
            # we need to check where this datapoint originally came from
            if (k in A_test.data):
                origintext = &#39;A_test&#39;
                origin = A_test
            elif (k in B.data):
                origintext = &#39;B&#39;
                origin = B
            else:
                print(&#39;Lost Datapoint!!&#39;, k)
                continue

            p = Point(origin.data[k])
            p.id = k

            M.remove_and_add(origin, A_train, p)
            removed_counter += 1

            # now fill up the origin from Z
            if fillup:
                Z_uniq_ids = list(Z.data.keys())
                Z_uniq_id = np.random.choice(Z_uniq_ids, replace=False)

                p = Point(Z.data[Z_uniq_id])
                p.id = Z_uniq_id

                M.remove_and_add(Z, origin, p)
                filled_counter += 1

        print(&#39;Removed:&#39;, removed_counter, &#39;Filled:&#39;, filled_counter)

        if self.store_after_each_step:
            M.save(os.path.join(self.workingdir, &#39;M_step8.pickle&#39;))

    def run(self,
            images,
            masks,
            weights,
            runs=1,
            patience_counter=2,
            percent_to_replace=30):
        # assert that len of images and masks is the same
        assert len(images) == len(masks)
        dataset_size = len(images)
        self.setup_data(images=images, masks=masks,
                        dataset_size=dataset_size,
                        weights=weights)

        for run in range(runs):
            print(&#39;******&#39;)
            print(&#39;Loop&#39;, run)
            t0 = time.time()
            self.run_classifier(patience_counter=patience_counter)
            self.run_discriminator()
            l = self.find_machine_labels()
            if l == 0:
                print(&#39;No more machine labels.&#39;)
                print(&#39;TOOK&#39;, time.time() - t0, &#39;seconds&#39;)
                break
            self.relabel(percent_to_replace=percent_to_replace)
            print(&#39;TOOK&#39;, time.time() - t0, &#39;seconds&#39;)
            print(&#39;==== DONE LOOP&#39;, run, &#39;====&#39;)

    #
    # PLOT!
    #
    def plot(self):

        x = range(len(self.classifier_scores))
        y1 = [v[1] for v in self.classifier_scores]
        y2 = [v[1] for v in self.discriminator_scores]

        Util.plot_accuracies(x, y1, y2)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="gp2.runner.Runner.create_C_dataset"><code class="name flex">
<span>def <span class="ident">create_C_dataset</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Create the C dataset from the classifier predictions (internal!).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_C_dataset(self):
    &#34;&#34;&#34; Create the C dataset from the classifier predictions (internal!).&#34;&#34;&#34;
    M = self.M

    A_test = M.get(&#39;A_test&#39;)
    A_test_pred = M.get(&#39;A_test_pred&#39;)
    B = M.get(&#39;B&#39;)

    A_test_images_only_, A_test_images_only_ids = A_test.to_array()
    A_test_images_only_ = A_test_images_only_[:, :, :, 0].astype(np.uint8)

    A_test_pred_, A_test_pred_ids = A_test_pred.to_array()
    A_test_pred_ = A_test_pred_.astype(np.uint8)

    A_test_with_pred_ = np.stack(
        (A_test_images_only_, A_test_pred_[:, :, :, 0]), axis=-1)

    #
    # CREATE C DATASET
    #
    B_, B_ids = B.to_array()

    C_size = (2 * B_.shape[0], B_.shape[1], B_.shape[2])
    C_images_ = np.zeros((C_size + (B_.shape[3],)), dtype=B_.dtype)

    C_images_[0:A_test_with_pred_.shape[0]] = A_test_with_pred_
    C_images_[A_test_with_pred_.shape[0]:] = B_

    C_labels_ = np.empty((C_size + (1,)), dtype=np.bool)
    C_labels_[0:B_.shape[0], 0, 0, 0] = 1
    C_labels_[B_.shape[0]:, 0, 0, 0] = 0

    C_ = np.concatenate((C_images_, C_labels_), axis=-1)

    # combine the uniq ids from A_test_pred and B
    C_ids = A_test_pred_ids + B_ids

    C = Collection.from_list(C_, C_ids)

    M.register(C, &#39;C&#39;)

    if self.store_after_each_step:
        M.save(os.path.join(self.workingdir, &#39;M_step2.pickle&#39;))</code></pre>
</details>
</dd>
<dt id="gp2.runner.Runner.create_C_train_val_test_split"><code class="name flex">
<span>def <span class="ident">create_C_train_val_test_split</span></span>(<span>self, train_count=300, val_count=100, test_count=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Create the C train/val/test split from the C dataset (internal!).
Parameters</p>
<hr>
<dl>
<dt><strong><code>train_count</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of training samples.</dd>
<dt><strong><code>val_count</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of validation samples.</dd>
<dt><strong><code>test_count</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of test samples.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_C_train_val_test_split(self,
                                  train_count=300,
                                  val_count=100,
                                  test_count=100):
    &#34;&#34;&#34; Create the C train/val/test split from the C dataset (internal!).
    Parameters
    ----------
    train_count : int
        Number of training samples.
    val_count : int
        Number of validation samples.
    test_count : int
        Number of test samples.
    Returns
    -------
    None
    &#34;&#34;&#34;

    M = self.M

    C = M.get(&#39;C&#39;)
    # we need to shuffle in connection land to keep track of the ids
    C.shuffle()

    C_, C_ids = C.to_array()
    C_train_, C_val_, C_test_ = Util.create_train_val_test_split(
        C_, train_count=train_count, val_count=val_count,
        test_count=test_count, shuffle=False)

    C_train_ids = C_ids[0:train_count]
    C_val_ids = C_ids[train_count:train_count + val_count]
    C_test_ids = \
        C_ids[train_count + val_count:train_count + val_count + test_count]

    C_train = Collection.from_list(C_train_, C_train_ids)
    C_val = Collection.from_list(C_val_, C_val_ids)
    C_test = Collection.from_list(C_test_, C_test_ids)

    M.register(C_train, &#39;C_train&#39;)
    M.register(C_val, &#39;C_val&#39;)
    M.register(C_test, &#39;C_test&#39;)

    if self.store_after_each_step:
        M.save(os.path.join(self.workingdir, &#39;M_step3.pickle&#39;))</code></pre>
</details>
</dd>
<dt id="gp2.runner.Runner.find_machine_labels"><code class="name flex">
<span>def <span class="ident">find_machine_labels</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This finds all machine labels, as indicated from the Discriminator
and create dataset D.
Returns number of machine labels found.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_machine_labels(self):
    &#34;&#34;&#34; This finds all machine labels, as indicated from the Discriminator
    and create dataset D.  Returns number of machine labels found.
    &#34;&#34;&#34;
    M = self.M

    C_test = M.get(&#39;C_test&#39;)
    C_test_pred = M.get(&#39;C_test_pred&#39;)

    C_test_, C_test_ids = C_test.to_array()
    C_test_pred_, C_test_pred_ids = C_test_pred.to_array()

    all_machine_labels_indices = np.where(C_test_pred_ == 1)[0]

    assert (C_test_ids == C_test_pred_ids)  # must be the same

    #
    # CREATE D DATASET
    #
    D_ = np.empty(((len(all_machine_labels_indices),) + C_test_.shape[1:]),
                  dtype=C_test_.dtype)
    D_ids = []

    for i, p in enumerate(all_machine_labels_indices):
        D_[i] = C_test_[p]
        D_ids.append(C_test_ids[p])

    if len(all_machine_labels_indices) == 0:
        print(&#39;No machine labels found. Skipping step 6.&#39;)
        return 0

    assert (np.all(
        D_[0] == C_test_[all_machine_labels_indices[0]]))  # quick check

    assert (D_ids[1] == C_test_ids[all_machine_labels_indices[1]])

    D = Collection.from_list(D_, D_ids)

    M.register(D, &#39;D&#39;)

    if self.store_after_each_step:
        M.save(os.path.join(self.workingdir, &#39;M_step6.pickle&#39;))

    return len(all_machine_labels_indices)</code></pre>
</details>
</dd>
<dt id="gp2.runner.Runner.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self):

    x = range(len(self.classifier_scores))
    y1 = [v[1] for v in self.classifier_scores]
    y2 = [v[1] for v in self.discriminator_scores]

    Util.plot_accuracies(x, y1, y2)</code></pre>
</details>
</dd>
<dt id="gp2.runner.Runner.predict_discriminator"><code class="name flex">
<span>def <span class="ident">predict_discriminator</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Predict using the Discriminator (internal!)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_discriminator(self):
    &#34;&#34;&#34; Predict using the Discriminator (internal!) &#34;&#34;&#34;
    M = self.M

    C_test = M.get(&#39;C_test&#39;)
    C_test_, C_test_ids = C_test.to_array()
    X_test_images_ = C_test_[:, :, :, 0]
    X_test_masks_ = C_test_[:, :, :, 1]
    y_test_ = C_test_[:, 0, 0, 2]

    cnnd = self.discriminator
    print(&#39;Testing the discriminator...&#39;)
    predictions, scores = cnnd.predict(X_test_images_, X_test_masks_,
                                       y_test_)

    self.discriminator_scores.append(scores)

    C_test_pred = Collection.from_list(predictions, C_test_ids)

    M.register(C_test_pred, &#39;C_test_pred&#39;)

    if self.store_after_each_step:
        M.save(os.path.join(self.workingdir, &#39;M_step5.pickle&#39;))</code></pre>
</details>
</dd>
<dt id="gp2.runner.Runner.relabel"><code class="name flex">
<span>def <span class="ident">relabel</span></span>(<span>self, percent_to_replace=30)</span>
</code></dt>
<dd>
<div class="desc"><p>Relabels a subset of Dataset D
Parameters</p>
<hr>
<dl>
<dt><strong><code>percent_to_replace</code></strong> :&ensp;<code>int</code></dt>
<dd>Percentage of D to relabel</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def relabel(self, percent_to_replace=30):
    &#34;&#34;&#34; Relabels a subset of Dataset D
    Parameters
    ----------
    percent_to_replace : int
        Percentage of D to relabel
    Returns
    -------
    None
    &#34;&#34;&#34;

    M = self.M

    D = M.get(&#39;D&#39;)

    # check that D in not NoneType
    if D is None:
        print(
            &#39;D is empty. Dataset may be too complex for this method. Skipping step 7.&#39;)
        return

    D_, D_ids = D.to_array()
    # TODO: Check why these are here if not used
    D_images = D_[:, :, :, 0]
    D_masks = D_[:, :, :, 1]
    D_labels = D_[:, 0, 0, 2]

    selected_ids = list(np.random.choice(D_ids, len(D_ids) // int(
        100 / percent_to_replace), replace=False))

    print(&#39;Replacing&#39;, len(selected_ids), &#39;from&#39;, len(D_ids), &#39;!&#39;)

    D_relabeled_ = np.empty((len(selected_ids),) + D_.shape[1:],
                            dtype=D_.dtype)

    A_test = M.get(&#39;A_test&#39;)
    B = M.get(&#39;B&#39;)

    uniqids_in_D = list(D.data.keys())

    for i, k in enumerate(selected_ids):
        # i is running number 0..len(selected_ids)
        # k is the uniqid of a datapoint

        # j is the position of the uniqid in D
        j = uniqids_in_D.index(k)

        # grab image
        image = D_[j, :, :, 0]
        label = D_[j, 0, 0, 2]

        origin = &#39;&#39;
        if k in A_test.data:
            origin = &#39;A_test&#39;
        elif k in B.data:
            origin = &#39;B&#39;
        else:
            print(&#39;Lost Datapoint!!&#39;, k)
            continue

        ### SIMULATION CASE -&gt; just grab ground truth###
        ### OTHERWISE THIS IS THE ENTRYPOINT FOR MANUAL RE-LABELING ###
        relabeled = M.get(origin).data[k][:, :, 1]

        D_relabeled_[i, :, :, 0] = image
        D_relabeled_[i, :, :, 1] = relabeled
        D_relabeled_[i, 0, 0, 2] = label

    print(&#39;D_relabeled_&#39;, D_relabeled_.shape[0])

    D_relabeled = Collection.from_list(D_relabeled_, selected_ids)

    M.register(D_relabeled, &#39;D_relabeled&#39;)

    if self.store_after_each_step:
        M.save(os.path.join(self.workingdir, &#39;M_step7.pickle&#39;))

    self.update_A_train()</code></pre>
</details>
</dd>
<dt id="gp2.runner.Runner.run"><code class="name flex">
<span>def <span class="ident">run</span></span>(<span>self, images, masks, weights, runs=1, patience_counter=2, percent_to_replace=30)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run(self,
        images,
        masks,
        weights,
        runs=1,
        patience_counter=2,
        percent_to_replace=30):
    # assert that len of images and masks is the same
    assert len(images) == len(masks)
    dataset_size = len(images)
    self.setup_data(images=images, masks=masks,
                    dataset_size=dataset_size,
                    weights=weights)

    for run in range(runs):
        print(&#39;******&#39;)
        print(&#39;Loop&#39;, run)
        t0 = time.time()
        self.run_classifier(patience_counter=patience_counter)
        self.run_discriminator()
        l = self.find_machine_labels()
        if l == 0:
            print(&#39;No more machine labels.&#39;)
            print(&#39;TOOK&#39;, time.time() - t0, &#39;seconds&#39;)
            break
        self.relabel(percent_to_replace=percent_to_replace)
        print(&#39;TOOK&#39;, time.time() - t0, &#39;seconds&#39;)
        print(&#39;==== DONE LOOP&#39;, run, &#39;====&#39;)</code></pre>
</details>
</dd>
<dt id="gp2.runner.Runner.run_classifier"><code class="name flex">
<span>def <span class="ident">run_classifier</span></span>(<span>self, patience_counter=2)</span>
</code></dt>
<dd>
<div class="desc"><p>(Re-)Train the classifier.
Parameters</p>
<hr>
<dl>
<dt><strong><code>patience_counter</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of epochs to wait before early stopping.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_classifier(self, patience_counter=2):
    &#34;&#34;&#34; (Re-)Train the classifier.
    Parameters
    ----------
    patience_counter : int
        Number of epochs to wait before early stopping.
    Returns
    -------
    None
    &#34;&#34;&#34;
    M = self.M

    A_train = M.get(&#39;A_train&#39;)
    A_val = M.get(&#39;A_val&#39;)
    A_test = M.get(&#39;A_test&#39;)

    #
    # ACTUAL CLASSIFIER TRAINING
    #
    u = self.classifier

    X_train_, X_train_ids = A_train.to_array()
    X_train_ = X_train_[:, :, :, 0].astype(np.float32)

    y_train_, y_train_ids = A_train.to_array()
    y_train_ = y_train_[:, :, :, 1].astype(np.float32)

    X_val_, X_val_ids = A_val.to_array()
    X_val_ = X_val_[:, :, :, 0].astype(np.float32)

    y_val_, y_val_ids = A_val.to_array()
    y_val_ = y_val_[:, :, :, 1].astype(np.float32)

    history = u.train(X_train_, y_train_, X_val_, y_val_,
                      patience_counter=patience_counter)

    X_test_, X_test_ids = A_test.to_array()
    X_test__ = X_test_[:, :, :, 0].astype(np.float32)
    y_test_ = X_test_[:, :, :, 1].astype(np.float32)

    print(&#39;Testing the classifier...&#39;)
    predictions, scores = u.predict(X_test__, y_test_)

    #
    # A_TEST PREDICTION
    #
    A_test_pred = Collection.from_list(predictions, X_test_ids)

    M.register(A_test_pred, &#39;A_test_pred&#39;)

    self.classifier_scores.append(scores)

    if self.store_after_each_step:
        M.save(os.path.join(self.workingdir, &#39;M_step1.pickle&#39;))</code></pre>
</details>
</dd>
<dt id="gp2.runner.Runner.run_discriminator"><code class="name flex">
<span>def <span class="ident">run_discriminator</span></span>(<span>self, train_ratio=0.4, val_ratio=0.1, test_ratio=0.5, threshold=1e-06)</span>
</code></dt>
<dd>
<div class="desc"><p>Train the discriminator using C_train/C_val. If the discriminator was
trained, this will just predict.
Parameters</p>
<hr>
<dl>
<dt><strong><code>train_ratio</code></strong> :&ensp;<code>float</code></dt>
<dd>Ratio of training samples.</dd>
<dt><strong><code>val_ratio</code></strong> :&ensp;<code>float</code></dt>
<dd>Ratio of validation samples.</dd>
<dt><strong><code>test_ratio</code></strong> :&ensp;<code>float</code></dt>
<dd>Ratio of test samples.</dd>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code></dt>
<dd>Threshold for the sum of train_ratio, val_ratio, and test_ratio.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_discriminator(self, train_ratio=0.4, val_ratio=0.1, test_ratio=0.5,
                      threshold=1e-6):
    &#34;&#34;&#34; Train the discriminator using C_train/C_val. If the discriminator was
    trained, this will just predict.
    Parameters
    ----------
    train_ratio : float
        Ratio of training samples.
    val_ratio : float
        Ratio of validation samples.
    test_ratio : float
        Ratio of test samples.
    threshold : float
        Threshold for the sum of train_ratio, val_ratio, and test_ratio.
    Returns
    -------
    None
    &#34;&#34;&#34;
    # Check that the sum of the ratios is approximately equal to 1
    if not (
            1 - threshold &lt;= train_ratio + val_ratio + test_ratio &lt;= 1 + threshold):
        raise ValueError(
            &#34;The sum of train_ratio, val_ratio, and test_ratio must be approximately equal to 1&#34;)

    self.create_C_dataset()

    dataset_size = self.dataset_size
    weights = self.weights

    train_count = int(0.2 * train_ratio * dataset_size)
    val_count = int(0.2 * val_ratio * dataset_size)
    test_count = int(0.2 * test_ratio * dataset_size)

    if weights:
        train_count = int(weights[&#39;B&#39;] * weights[&#39;B_train&#39;] * dataset_size)
        val_count = int(weights[&#39;B&#39;] * weights[&#39;B_val&#39;] * dataset_size)
        test_count = int(weights[&#39;B&#39;] * weights[&#39;B_test&#39;] * dataset_size)

    self.create_C_train_val_test_split(train_count, val_count, test_count)

    M = self.M

    cnnd = self.discriminator

    C_train = M.get(&#39;C_train&#39;)
    C_val = M.get(&#39;C_val&#39;)

    C_train_, C_train_ids = C_train.to_array()
    X_train_images_ = C_train_[:, :, :, 0]
    X_train_masks_ = C_train_[:, :, :, 1]
    y_train_ = C_train_[:, 0, 0, 2]

    C_val_, C_val_ids = C_val.to_array()
    X_val_images_ = C_val_[:, :, :, 0]
    X_val_masks_ = C_val_[:, :, :, 1]
    y_val_ = C_val_[:, 0, 0, 2]

    cnnd.train(X_train_images_, X_train_masks_, y_train_, X_val_images_,
               X_val_masks_, y_val_)
    self.discriminator = cnnd

    if self.store_after_each_step:
        M.save(os.path.join(self.workingdir, &#39;M_step4.pickle&#39;))

    self.predict_discriminator()</code></pre>
</details>
</dd>
<dt id="gp2.runner.Runner.setup_data"><code class="name flex">
<span>def <span class="ident">setup_data</span></span>(<span>self, images, masks, dataset_size=1000, weights=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Set up the data for training.
Each dataset is composed of three parts:
A_: data to train/val/test the classifier </p>
<pre><code>B_: expert labels to feed directly into the discriminator

Z_: a repository of additional data that can further train the
classifier
</code></pre>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>images</code></strong> :&ensp;<code>list</code> of <code>np.ndarray</code></dt>
<dd>List of images to use for training.</dd>
<dt><strong><code>masks</code></strong> :&ensp;<code>list</code> of <code>np.ndarray</code></dt>
<dd>List of masks to use for training.</dd>
<dt><strong><code>dataset_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of images to use for training.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>dict</code></dt>
<dd>Weights to use for training. If None, will use the default weights.
Weights should be a dictionary with keys 'A', 'B', 'Z', 'A_test'.
The weights should sum to 1.0.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def setup_data(self, images, masks, dataset_size=1000, weights=None):
    &#34;&#34;&#34; Set up the data for training.
    Each dataset is composed of three parts:
        A_: data to train/val/test the classifier \n
        B_: expert labels to feed directly into the discriminator \n
        Z_: a repository of additional data that can further train the
        classifier
    Parameters
    ----------
    images : list of np.ndarray
        List of images to use for training.
    masks : list of np.ndarray
        List of masks to use for training.
    dataset_size : int
        Number of images to use for training.
    weights : dict
        Weights to use for training. If None, will use the default weights.
        Weights should be a dictionary with keys &#39;A&#39;, &#39;B&#39;, &#39;Z&#39;, &#39;A_test&#39;.
        The weights should sum to 1.0.
    Returns
    -------
    None
    &#34;&#34;&#34;
    M = self.M

    self.dataset_size = dataset_size
    self.weights = weights

    if weights:
        validate_weights(weights)

    A_, B_, Z_ = Util.create_A_B_Z_split(images, masks,
                                         dataset_size=dataset_size,
                                         weights=weights)

    A = Collection.from_list(A_)
    B = Collection.from_list(B_)
    Z = Collection.from_list(Z_)

    M.register(A, &#39;A&#39;)  # we might not need to save this one here
    M.register(B, &#39;B&#39;)
    M.register(Z, &#39;Z&#39;)

    A = M.get(&#39;A&#39;)
    A_, A_ids = A.to_array()

    # if no weights configured, fallback
    train_count = int(0.4 * 0.1 * dataset_size)
    val_count = int(0.4 * 0.4 * dataset_size)
    test_count = int(0.4 * 0.5 * dataset_size)

    if weights:
        train_count = int(weights[&#39;A&#39;] * weights[&#39;A_train&#39;] * dataset_size)
        val_count = int(weights[&#39;A&#39;] * weights[&#39;A_val&#39;] * dataset_size)
        test_count = int(weights[&#39;A&#39;] * weights[&#39;A_test&#39;] * dataset_size)

    A_train_, A_val_, A_test_ = Util.create_train_val_test_split(
        A_, train_count=train_count, val_count=val_count,
        test_count=test_count, shuffle=False)
    A_train_ids = A_ids[0:train_count]
    A_val_ids = A_ids[train_count:train_count + val_count]
    A_test_ids = A_ids[
                 train_count + val_count:train_count + val_count + test_count]

    A_train = Collection.from_list(A_train_, A_train_ids)  # COLLECTION LAND
    A_val = Collection.from_list(A_val_, A_val_ids)
    A_test = Collection.from_list(A_test_, A_test_ids)

    M.register(A_train, &#39;A_train&#39;)
    M.register(A_val, &#39;A_val&#39;)
    M.register(A_test, &#39;A_test&#39;)</code></pre>
</details>
</dd>
<dt id="gp2.runner.Runner.update_A_train"><code class="name flex">
<span>def <span class="ident">update_A_train</span></span>(<span>self, balance=True, fillup=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Update A_train with selected points from D. Then, remove D from B
and A_test (wherever it was!). Fill-up both B and A_test (internal!).
Parameters</p>
<hr>
<dl>
<dt><strong><code>balance</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, balance A_train with B and A_test</dd>
<dt><strong><code>fillup</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, fill-up B and A_test with points from A_train</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_A_train(self, balance=True, fillup=True):
    &#34;&#34;&#34; Update A_train with selected points from D. Then, remove D from B
    and A_test (wherever it was!). Fill-up both B and A_test (internal!).
    Parameters
    ----------
    balance : bool
        If True, balance A_train with B and A_test
    fillup : bool
        If True, fill-up B and A_test with points from A_train
    Returns
    -------
    None
    &#34;&#34;&#34;
    M = self.M

    D_relabeled = M.get(&#39;D_relabeled&#39;)

    A_train = M.get(&#39;A_train&#39;)
    A_test = M.get(&#39;A_test&#39;)
    B = M.get(&#39;B&#39;)

    Z = M.get(&#39;Z&#39;)  # repository

    removed_counter = 0
    filled_counter = 0

    point_ids = list(D_relabeled.data.keys())

    print(&#39;point ids&#39;, len(point_ids))

    # Move points from A_test to A_train
    for k in point_ids:
        # we need to check where this datapoint originally came from
        if (k in A_test.data):
            origintext = &#39;A_test&#39;
            origin = A_test
        elif (k in B.data):
            origintext = &#39;B&#39;
            origin = B
        else:
            print(&#39;Lost Datapoint!!&#39;, k)
            continue

        p = Point(origin.data[k])
        p.id = k

        M.remove_and_add(origin, A_train, p)
        removed_counter += 1

        # now fill up the origin from Z
        if fillup:
            Z_uniq_ids = list(Z.data.keys())
            Z_uniq_id = np.random.choice(Z_uniq_ids, replace=False)

            p = Point(Z.data[Z_uniq_id])
            p.id = Z_uniq_id

            M.remove_and_add(Z, origin, p)
            filled_counter += 1

    print(&#39;Removed:&#39;, removed_counter, &#39;Filled:&#39;, filled_counter)

    if self.store_after_each_step:
        M.save(os.path.join(self.workingdir, &#39;M_step8.pickle&#39;))</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="gp2" href="index.html">gp2</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="gp2.runner.validate_weights" href="#gp2.runner.validate_weights">validate_weights</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="gp2.runner.Runner" href="#gp2.runner.Runner">Runner</a></code></h4>
<ul class="">
<li><code><a title="gp2.runner.Runner.create_C_dataset" href="#gp2.runner.Runner.create_C_dataset">create_C_dataset</a></code></li>
<li><code><a title="gp2.runner.Runner.create_C_train_val_test_split" href="#gp2.runner.Runner.create_C_train_val_test_split">create_C_train_val_test_split</a></code></li>
<li><code><a title="gp2.runner.Runner.find_machine_labels" href="#gp2.runner.Runner.find_machine_labels">find_machine_labels</a></code></li>
<li><code><a title="gp2.runner.Runner.plot" href="#gp2.runner.Runner.plot">plot</a></code></li>
<li><code><a title="gp2.runner.Runner.predict_discriminator" href="#gp2.runner.Runner.predict_discriminator">predict_discriminator</a></code></li>
<li><code><a title="gp2.runner.Runner.relabel" href="#gp2.runner.Runner.relabel">relabel</a></code></li>
<li><code><a title="gp2.runner.Runner.run" href="#gp2.runner.Runner.run">run</a></code></li>
<li><code><a title="gp2.runner.Runner.run_classifier" href="#gp2.runner.Runner.run_classifier">run_classifier</a></code></li>
<li><code><a title="gp2.runner.Runner.run_discriminator" href="#gp2.runner.Runner.run_discriminator">run_discriminator</a></code></li>
<li><code><a title="gp2.runner.Runner.setup_data" href="#gp2.runner.Runner.setup_data">setup_data</a></code></li>
<li><code><a title="gp2.runner.Runner.update_A_train" href="#gp2.runner.Runner.update_A_train">update_A_train</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>